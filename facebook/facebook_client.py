"""
Facebook Scraper Client
–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –ø—É–±–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü Facebook —á–µ—Ä–µ–∑ Playwright
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ Playwright –¥–ª—è —Å–∫—Ä–∞–ø–ø–∏–Ω–≥–∞ (–±–µ–∑ facebook-scraper)
"""
import asyncio
import logging
import os
import re
from typing import Dict, Any, Optional, List
from datetime import datetime

logger = logging.getLogger(__name__)

try:
    from bs4 import BeautifulSoup
except ImportError:
    logger.warning("BeautifulSoup –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–∞—Ä—Å–∏–Ω–≥ HTML –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install beautifulsoup4")
    BeautifulSoup = None

try:
    from playwright.async_api import async_playwright, Browser, Page
except ImportError:
    logger.error("Playwright –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install playwright && playwright install chromium")
    async_playwright = None


class FacebookScraperClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Facebook —á–µ—Ä–µ–∑ Playwright —Å–∫—Ä–µ–π–ø–∏–Ω–≥"""
    
    def __init__(self, cookies: Optional[str] = None, user_agent: Optional[str] = None, 
                 browser_channel: Optional[str] = None, browser_executable_path: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            cookies: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å cookies (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –æ–±—Ö–æ–¥–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
            user_agent: User-Agent –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            browser_channel: –ö–∞–Ω–∞–ª –±—Ä–∞—É–∑–µ—Ä–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "chrome", "msedge", "chrome-beta")
                           –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: "chrome", "chrome-beta", "msedge", "msedge-beta", "msedge-dev"
            browser_executable_path: –ü—É—Ç—å –∫ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–º—É —Ñ–∞–π–ª—É –±—Ä–∞—É–∑–µ—Ä–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä)
        """
        self.cookies = cookies
        self.browser_channel = browser_channel
        self.browser_executable_path = browser_executable_path
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π User-Agent –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
        self.user_agent = user_agent or (
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0.0.0 Safari/537.36"
        )
        # self.user_agent = user_agent or (
        #     "Mozilla/5.0 (iPhone; CPU iPhone OS 17_4_1 like Mac OS X)" 
        #     "AppleWebKit/605.1.15 (KHTML, like Gecko) "
        #     "Version/17.4 Mobile/15E148 Safari/604.1"
        # )
    
    def _load_cookies_for_playwright(self) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å cookies –∏–∑ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Playwright
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å cookies –¥–ª—è Playwright
        """
        playwright_cookies = []
        
        if not self.cookies:
            logger.debug("Cookies –Ω–µ —É–∫–∞–∑–∞–Ω—ã, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
            return playwright_cookies
        
        logger.info(f"üìÇ –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ —Ñ–∞–π–ª–∞: {self.cookies}")
        
        try:
            if not os.path.exists(self.cookies):
                logger.warning(f"‚ö†Ô∏è  –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.cookies}")
                return playwright_cookies
            
            with open(self.cookies, 'r') as f:
                lines = f.readlines()
                logger.debug(f"   –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(lines)} —Å—Ç—Ä–æ–∫ –∏–∑ —Ñ–∞–π–ª–∞ cookies")
                
                for line_num, line in enumerate(lines, 1):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    parts = line.split('\t')
                    if len(parts) >= 7:
                        domain = parts[0].lstrip('.')
                        path = parts[2]
                        secure = parts[3] == 'TRUE'
                        expiration = int(parts[4]) if parts[4] != '0' else None
                        name = parts[5]
                        value = parts[6] if len(parts) > 6 else ''
                        
                        cookie = {
                            "name": name,
                            "value": value,
                            "domain": domain,
                            "path": path,
                            "secure": secure,
                        }
                        
                        if expiration:
                            cookie["expires"] = expiration
                        
                        playwright_cookies.append(cookie)
                        logger.debug(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω cookie: {name} –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}")
                    else:
                        logger.debug(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {line_num}: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–æ–∂–∏–¥–∞–µ—Ç—Å—è 7+ –ø–æ–ª–µ–π)")
            
            logger.info(f"‚úÖ –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à–µ–Ω: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(playwright_cookies)} cookies")
            if playwright_cookies:
                cookie_names = [c.get('name', 'unknown') for c in playwright_cookies]
                logger.info(f"   Cookie names: {', '.join(cookie_names)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ cookies: {e}", exc_info=True)
        
        return playwright_cookies
    
    def parse_comments_from_html(self, html_content: str, limit: int = 100) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ HTML-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã Facebook
        
        Args:
            html_content: HTML-—Å—Ç—Ä–æ–∫–∞ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ Facebook
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
        """
        if BeautifulSoup is None:
            raise ImportError("BeautifulSoup –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install beautifulsoup4")
        
        if not html_content or not html_content.strip():
            logger.warning("–ü–æ–ª—É—á–µ–Ω–∞ –ø—É—Å—Ç–∞—è HTML-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
            return {
                "comments": [],
                "total_count": 0
            }
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            comments = []
            
            # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ Facebook HTML
            # Facebook –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–æ–∏—Å–∫ –ø–æ data-ft –∞—Ç—Ä–∏–±—É—Ç–∞–º (—Å—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
            comment_elements = soup.find_all(attrs={"data-ft": re.compile(r".*top_level_post_id.*")})
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            if not comment_elements:
                comment_elements = soup.find_all('div', class_=re.compile(r'.*comment.*', re.I))
            
            # –í–∞—Ä–∏–∞–Ω—Ç 3: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å userContentWrapper
            if not comment_elements:
                comment_elements = soup.find_all('div', attrs={"data-testid": re.compile(r".*comment.*", re.I)})
            
            # –í–∞—Ä–∏–∞–Ω—Ç 4: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å role="article" (—á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
            if not comment_elements:
                comment_elements = soup.find_all('div', role="article")
            
            # –í–∞—Ä–∏–∞–Ω—Ç 5: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å data-sigil (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –º–æ–±–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏)
            if not comment_elements:
                comment_elements = soup.find_all(attrs={"data-sigil": re.compile(r".*comment.*", re.I)})
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(comment_elements)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
            
            for idx, element in enumerate(comment_elements[:limit]):
                try:
                    comment_data = self._extract_comment_data(element)
                    if comment_data and comment_data.get("text"):
                        comments.append(comment_data)
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è #{idx}: {e}")
                    continue
            
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(comments)} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–∑ HTML")
            
            return {
                "comments": comments,
                "total_count": len(comments)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ HTML –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {e}", exc_info=True)
            return {
                "comments": [],
                "total_count": 0,
                "error": str(e)
            }
    
    def _extract_comment_data(self, element) -> Optional[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –∏–∑ HTML-—ç–ª–µ–º–µ–Ω—Ç–∞
        
        Args:
            element: BeautifulSoup —ç–ª–µ–º–µ–Ω—Ç —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –∏–ª–∏ None
        """
        try:
            comment_data = {}
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            text_selectors = [
                'div[data-testid="comment"]',
                '.userContent',
                '[data-sigil="comment-body"]',
                '.comment-body',
                'span[dir="auto"]',
            ]
            
            text = None
            for selector in text_selectors:
                text_elem = element.select_one(selector)
                if text_elem:
                    text = text_elem.get_text(strip=True)
                    if text:
                        break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏
            if not text:
                # –ò—â–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —É–∑–ª—ã, –Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏ –∫–Ω–æ–ø–∫–∏
                text_parts = []
                for text_node in element.find_all(string=True):
                    parent = text_node.parent
                    if parent and parent.name not in ['a', 'button', 'script', 'style']:
                        text_part = text_node.strip()
                        if text_part:
                            text_parts.append(text_part)
                text = ' '.join(text_parts).strip()
            
            comment_data["text"] = text or ""
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞
            author_selectors = [
                'a[role="link"]',
                'strong a',
                'h3 a',
                '[data-hovercard-prefer-more-content-show="1"]',
                'a[href*="/user/"]',
                'a[href*="/profile.php"]',
            ]
            
            author = None
            author_id = None
            for selector in author_selectors:
                author_elem = element.select_one(selector)
                if author_elem:
                    author = author_elem.get_text(strip=True)
                    href = author_elem.get('href', '')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Å—Å—ã–ª–∫–∏
                    if '/user/' in href:
                        author_id = href.split('/user/')[-1].split('/')[0].split('?')[0]
                    elif 'profile.php?id=' in href:
                        author_id = href.split('profile.php?id=')[-1].split('&')[0]
                    if author:
                        break
            
            comment_data["author"] = author or ""
            comment_data["author_id"] = author_id or ""
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
            time_selectors = [
                'a[href*="/comment/"]',
                'a abbr',
                '[data-tooltip-content]',
                'a[title]',
            ]
            
            time_str = None
            for selector in time_selectors:
                time_elem = element.select_one(selector)
                if time_elem:
                    time_str = time_elem.get('title') or time_elem.get('data-tooltip-content') or time_elem.get_text(strip=True)
                    if time_str:
                        break
            
            comment_data["time"] = time_str or ""
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ª–∞–π–∫–æ–≤
            likes_selectors = [
                '[aria-label*="Like"]',
                '[data-sigil="reactions-count"]',
                '.like-count',
            ]
            
            likes = 0
            for selector in likes_selectors:
                likes_elem = element.select_one(selector)
                if likes_elem:
                    likes_text = likes_elem.get_text(strip=True)
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                    likes_match = re.search(r'(\d+)', likes_text.replace(',', '').replace('.', ''))
                    if likes_match:
                        try:
                            likes = int(likes_match.group(1))
                            break
                        except ValueError:
                            pass
            
            comment_data["likes"] = likes
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
            comment_id = element.get('id') or element.get('data-ft', '')
            if comment_id and isinstance(comment_id, str):
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å ID –∏–∑ data-ft JSON
                if 'top_level_post_id' in comment_id:
                    try:
                        import json
                        # data-ft –º–æ–∂–µ—Ç –±—ã—Ç—å JSON —Å—Ç—Ä–æ–∫–æ–π
                        ft_data = json.loads(comment_id) if comment_id.startswith('{') else {}
                        comment_id = ft_data.get('top_level_post_id', '')
                    except:
                        # –ï—Å–ª–∏ –Ω–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–µ—Ä–µ–∑ regex
                        id_match = re.search(r'top_level_post_id["\']?\s*:\s*["\']?(\d+)', comment_id)
                        if id_match:
                            comment_id = id_match.group(1)
            
            comment_data["comment_id"] = str(comment_id) if comment_id else ""
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ (replies) - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
            replies = []
            reply_elements = element.find_all('div', class_=re.compile(r'.*reply.*', re.I))
            for reply_elem in reply_elements[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤
                reply_data = self._extract_comment_data(reply_elem)
                if reply_data:
                    replies.append(reply_data)
            
            comment_data["replies"] = replies
            
            return comment_data
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è: {e}")
            return None
    
    async def fetch_and_parse_comments_with_browser(self, url: str, limit: int = 100, wait_time: int = 5) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä (Playwright) —Å —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–æ–º JavaScript –∏ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Å–∫—Ä–∞–ø–ø–∏–Ω–≥: –ø–∞—Ä—Å–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–∫—Ä–æ–ª–ª–∞,
        —Å–æ–±–∏—Ä–∞—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞.
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã Facebook —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            wait_time: –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if async_playwright is None:
            raise ImportError(
                "Playwright –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install playwright && playwright install chromium"
            )
        
        start_time = datetime.now()
        status = "started"
        
        try:
            logger.info(f"–ù–∞—á–∞–ª–æ —Å–∫—Ä–∞–ø–ø–∏–Ω–≥–∞: {url} (–ª–∏–º–∏—Ç: {limit})")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º cookies
            playwright_cookies = self._load_cookies_for_playwright()
            
            # –ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é
            mobile_url = url.replace("www.facebook.com", "m.facebook.com")
            
            all_comments = []  # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            seen_comment_ids = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            
            async with async_playwright() as p:
                status = "initializing_browser"
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—É—Å–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞
                launch_options = {"headless": False}
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–∞–Ω–∞–ª –±—Ä–∞—É–∑–µ—Ä–∞, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
                if self.browser_channel:
                    launch_options["channel"] = self.browser_channel
                    logger.info(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—Ä–∞—É–∑–µ—Ä: {self.browser_channel}")
                
                # –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
                elif self.browser_executable_path:
                    launch_options["executable_path"] = self.browser_executable_path
                    logger.info(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—Ä–∞—É–∑–µ—Ä –∏–∑: {self.browser_executable_path}")
                
                browser = await p.chromium.launch(**launch_options)
                context = await browser.new_context(
                    user_agent=self.user_agent,
                    viewport={"width": 1920, "height": 1080}
                )
                
                if playwright_cookies:
                    await context.add_cookies(playwright_cookies)
                
                page = await context.new_page()
                
                try:
                    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
                    screenshots_dir = "screenshots"
                    os.makedirs(screenshots_dir, exist_ok=True)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    await page.goto(mobile_url, wait_until="networkidle", timeout=30000)
                    await page.wait_for_timeout(wait_time * 1000)
                    
                    # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    screenshot_path = f"{screenshots_dir}/01_initial_load.png"
                    await page.screenshot(path=screenshot_path, full_page=False)
                    logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
                    
                    # –ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∞–ø–ø–∏–Ω–≥: —Å–∫—Ä–æ–ª–ª–∏–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥ –∏ –ø–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                    status = "scrolling_and_collecting"
                    
                    scroll_interval = 5000  # 5 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É —Å–∫—Ä–æ–ª–ª–∞–º–∏
                    max_scrolls = 3  # –ú–∞–∫—Å–∏–º—É–º 3 —Å–∫—Ä–æ–ª–ª–∞
                    no_new_comments_count = 0  # –°—á–µ—Ç—á–∏–∫ —Å–∫—Ä–æ–ª–ª–æ–≤ –±–µ–∑ –Ω–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                    max_no_new_comments = 2  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ 2 —Å–∫—Ä–æ–ª–ª–æ–≤ –±–µ–∑ –Ω–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                    
                    for i in range(max_scrolls):
                        logger.info(f"üîÑ –°–∫—Ä–æ–ª–ª #{i+1}/{max_scrolls}")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã Playwright –¥–ª—è —Å–∫—Ä–æ–ª–ª–∞
                        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —ç–∫—Ä–∞–Ω–∞ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–∫—Ä–æ–ª–ª–∞
                        viewport_size = page.viewport_size
                        if viewport_size:
                            scroll_height = viewport_size['height']
                        else:
                            scroll_height = await page.evaluate("window.innerHeight")
                        
                        # –°–∫—Ä–æ–ª–ª–∏–º –∫–æ–ª–µ—Å–æ–º –º—ã—à–∏ (–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ Playwright)
                        # –î–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∫—Ä–æ–ª–ª–æ–≤ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                        # await page.mouse.move(x=500, y=500)
                        # await page.wait_for_timeout(200)
                        # await page.mouse.wheel(0, 2500)
                        # await page.wait_for_timeout(2000)
                        # await page.mouse.wheel(0, 2500)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–æ–ª–ª
                        # await page.keyboard.press("PageDown")
                        # await page.keyboard.press("PageDown")
                        await page.keyboard.press("PageDown")
                        await page.evaluate("window.scrollBy(0, 1200)")
                        
                        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
                        # await page.keyboard.press('PageDown')
                        # –ñ–¥–µ–º 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                        await page.wait_for_timeout(scroll_interval)
                        
                        # –ü–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–∫—Ä–æ–ª–ª–∞ (—Å–æ–∫—Ä–∞—Ç–∏–ª–∏ –∏—Ç–µ—Ä–∞—Ü–∏–∏)
                        html_content = await page.content()
                        parsed_result = self.parse_comments_from_html(html_content, limit=limit)
                        new_comments = parsed_result.get('comments', [])
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                        if new_comments:
                            logger.info(f"–°–∫—Ä–æ–ª–ª #{i+1}: –Ω–∞–π–¥–µ–Ω–æ {len(new_comments)} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ HTML")
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –∫–∞–∫ –ø—Ä–∏–º–µ—Ä—ã (—Å–æ–∫—Ä–∞—Ç–∏–ª–∏ —Å 3 –¥–æ 2)
                            for idx, comment in enumerate(new_comments[:2], 1):
                                author = comment.get('author', '–ê–Ω–æ–Ω–∏–º') or '–ê–Ω–æ–Ω–∏–º'
                                text = comment.get('text', '') or ''
                                text_preview = text[:100] + '...' if len(text) > 100 else text
                                logger.info(f"  –ü—Ä–∏–º–µ—Ä #{idx}: –ê–≤—Ç–æ—Ä='{author}' | –¢–µ–∫—Å—Ç='{text_preview}'")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (—Å–æ–∫—Ä–∞—Ç–∏–ª–∏ –∏—Ç–µ—Ä–∞—Ü–∏–∏)
                        new_count = 0
                        comments_to_process = new_comments[:limit]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                        for comment in comments_to_process:
                            comment_key = f"{comment.get('author', '')}_{comment.get('text', '')[:50]}"
                            comment_id = comment.get('comment_id', '') or comment_key
                            
                            if comment_id not in seen_comment_ids and comment.get('text'):
                                seen_comment_ids.add(comment_id)
                                all_comments.append(comment)
                                new_count += 1
                                
                                if len(all_comments) >= limit:
                                    break
                        
                        if new_count > 0:
                            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {new_count} –Ω–æ–≤—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (–≤—Å–µ–≥–æ: {len(all_comments)})")
                            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–∫—Ä–æ–ª–ª–µ —Å –Ω–æ–≤—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
                            screenshot_path = f"{screenshots_dir}/02_scroll_{i+1:02d}_found_{new_count}_comments.png"
                            await page.screenshot(path=screenshot_path, full_page=False)
                            logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
                            no_new_comments_count = 0
                        else:
                            no_new_comments_count += 1
                            logger.info(f"–ù–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ({no_new_comments_count}/{max_no_new_comments})")
                        
                        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –∏–ª–∏ –Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                        if len(all_comments) >= limit:
                            logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {limit}")
                            break
                        
                        if no_new_comments_count >= max_no_new_comments:
                            logger.info(f"–ù–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ {max_no_new_comments} —Ä–∞–∑–∞ –ø–æ–¥—Ä—è–¥, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∫—Ä–æ–ª–ª–∏–Ω–≥")
                            break
                    
                    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç
                    screenshot_path = f"{screenshots_dir}/03_final_state.png"
                    await page.screenshot(path=screenshot_path, full_page=True)
                    logger.info(f"üì∏ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
                    
                    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                    html_content = await page.content()
                    parsed_result = self.parse_comments_from_html(html_content, limit=limit)
                    final_comments = parsed_result.get('comments', [])
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (—Å–æ–∫—Ä–∞—Ç–∏–ª–∏ –∏—Ç–µ—Ä–∞—Ü–∏–∏)
                    comments_to_process = final_comments[:limit]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                    for comment in comments_to_process:
                        comment_key = f"{comment.get('author', '')}_{comment.get('text', '')[:50]}"
                        comment_id = comment.get('comment_id', '') or comment_key
                        
                        if comment_id not in seen_comment_ids and comment.get('text'):
                            seen_comment_ids.add(comment_id)
                            all_comments.append(comment)
                            
                            if len(all_comments) >= limit:
                                break
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ –ª–∏–º–∏—Ç–∞
                    all_comments = all_comments[:limit]
                    
                    result = {
                        "comments": all_comments,
                        "total_count": len(all_comments)
                    }
                    
                finally:
                    await page.close()
                    await context.close()
                    await browser.close()
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            comments_count = result.get('total_count', 0)
            comments = result.get('comments', [])
            status = "completed" if comments_count > 0 else "completed_no_comments"
            
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Å—Ç–∞—Ç—É—Å
            result["url"] = url
            result["fetched_at"] = end_time.isoformat()
            result["started_at"] = start_time.isoformat()
            result["duration_seconds"] = round(duration, 2)
            result["method"] = "browser_rendering_incremental"
            result["status"] = status
            result["success"] = True
            
            logger.info(f"–°–∫—Ä–∞–ø–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {comments_count} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∑–∞ {duration:.2f} —Å–µ–∫")
            
            return result
            
        except Exception as e:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            status = "failed"
            
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–ø–∏–Ω–≥–∞: {str(e)}")
            
            return {
                "url": url,
                "status": status,
                "success": False,
                "error": str(e),
                "started_at": start_time.isoformat(),
                "fetched_at": end_time.isoformat(),
                "duration_seconds": round(duration, 2),
                "comments": [],
                "total_count": 0
            }
    
    async def fetch_and_parse_comments_from_url(self, url: str, limit: int = 100) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å HTML —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Facebook —á–µ—Ä–µ–∑ HTTP –∏ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        (–±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞, —Ç–æ–ª—å–∫–æ HTTP –∑–∞–ø—Ä–æ—Å)
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã Facebook —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        import httpx
        
        start_time = datetime.now()
        status = "started"
        
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ HTML —á–µ—Ä–µ–∑ HTTP: {url}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º cookies –µ—Å–ª–∏ –µ—Å—Ç—å
            cookies_dict = {}
            if self.cookies:
                try:
                    with open(self.cookies, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if not line or line.startswith('#'):
                                continue
                            parts = line.split('\t')
                            if len(parts) >= 7:
                                domain = parts[0].lstrip('.')
                                name = parts[5]
                                value = parts[6] if len(parts) > 6 else ''
                                if 'facebook.com' in domain:
                                    cookies_dict[name] = value
                except Exception as e:
                    logger.debug(f"Could not load cookies: {e}")
            
            # –ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é
            mobile_url = url.replace("www.facebook.com", "m.facebook.com")
            
            async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
                # headers = {
                #     "User-Agent": self.user_agent,
                #     "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                #     "Accept-Language": "en-US,en;q=0.5",
                # }
                headers = {         # –°–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ: —Å–≤–µ–∂–∏–π User-Agent –æ—Ç iPhone
                    "User-Agent": self.user_agent,
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                    "Accept-Language": "en-US,en;q=0.9",
                    "Accept-Encoding": "gzip, deflate, br",
                }
                
                try:
                    response = await client.get(mobile_url, headers=headers, cookies=cookies_dict)
                except Exception:
                    # –ï—Å–ª–∏ –º–æ–±–∏–ª—å–Ω–∞—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—É—é
                    try:
                        response = await client.get(url, headers=headers, cookies=cookies_dict)
                    except Exception:
                        response = await client.get(url, headers=headers)
                
                response.raise_for_status()
                html_content = response.text
            
            status = "parsing_comments"
            logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–∑ HTML...")
            result = self.parse_comments_from_html(html_content, limit=limit)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            comments_count = result.get('total_count', 0)
            status = "completed" if comments_count > 0 else "completed_no_comments"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            result["url"] = url
            result["fetched_at"] = end_time.isoformat()
            result["started_at"] = start_time.isoformat()
            result["duration_seconds"] = round(duration, 2)
            result["html_size"] = len(html_content)
            result["method"] = "http_request"
            result["status"] = status
            result["success"] = True
            
            logger.info(f"HTTP —Å–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {comments_count} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∑–∞ {duration:.2f} —Å–µ–∫")
            
            return result
            
        except Exception as e:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            status = "failed"
            
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ HTTP —Å–∫—Ä–∞–ø–∏–Ω–≥–µ: {e}")
            
            return {
                "url": url,
                "status": status,
                "success": False,
                "error": str(e),
                "started_at": start_time.isoformat(),
                "fetched_at": end_time.isoformat(),
                "duration_seconds": round(duration, 2),
                "comments": [],
                "total_count": 0
            }
    
